Question 1

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
import yfinance as yf
# Step 1: Download the dataset
ticker = 'AAPL'
data = yf.download(ticker, start='2015-01-01', end='2023-01-01')
data = data[['Close']]
# Step 2: Preprocess the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)
# Step 3: Create sequences
sequence_length = 60
X = []
y = []
for i in range(sequence_length, len(scaled_data)):
 X.append(scaled_data[i-sequence_length:i, 0])
 y.append(scaled_data[i, 0])
X, y = np.array(X), np.array(y)
X = np.reshape(X, (X.shape[0], X.shape[1], 1))
# Step 4: Split the data
split_ratio = 0.8
train_size = int(len(X) * split_ratio)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]
# Step 5: Build the LSTM model
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(units=25))
model.add(Dense(units=1))
# Step 6: Compile and train the model
model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=20, batch_size=32)
# Step 7: Evaluate the model
predictions = model.predict(X_test)
predictions = scaler.inverse_transform(predictions)
# Plotting the results
plt.figure(figsize=(16, 8))
plt.plot(data.index[train_size + sequence_length:], data['Close'][train_size + sequence_length:], 
color='blue', label='Actual Prices')
plt.plot(data.index[train_size + sequence_length:], predictions, color='red', label='Predicted 
Prices')
plt.title(f'{ticker} Stock Price Prediction')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.legend()
plt.show()
# Step 8: Make future predictions (optional)
# Use the last sequence to predict the next price
last_sequence = scaled_data[-sequence_length:]
last_sequence = np.reshape(last_sequence, (1, sequence_length, 1))
next_price_scaled = model.predict(last_sequence)
next_price = scaler.inverse_transform(next_price_scaled)
print(f'The predicted next price for {ticker} is: {next_price[0, 0]:.2f} USD')



Question 2:

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import make_classification
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import tensorflow as tf
from tensorflow.keras import layers, models
# Step 1: Create and Prepare Your Data
# Generate a synthetic dataset
X, y = make_classification(n_samples=1000, # Number of samples
 n_features=20, # Number of features
 n_informative=15, # Number of informative features
 n_redundant=5, # Number of redundant features
 n_classes=3, # Number of classes
 random_state=42)
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Normalize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
# Step 2: Build the Autoencoder
# Define the autoencoder architecture
input_dim = X_train.shape[1] # Number of features
# Encoder
input_layer = layers.Input(shape=(input_dim,))
encoded = layers.Dense(64, activation='relu')(input_layer)
encoded = layers.Dense(32, activation='relu')(encoded)
encoded = layers.Dense(16, activation='relu')(encoded)
# Latent space
latent_space = layers.Dense(8, activation='relu')(encoded)
# Decoder
decoded = layers.Dense(16, activation='relu')(latent_space)
decoded = layers.Dense(32, activation='relu')(decoded)
decoded = layers.Dense(64, activation='relu')(decoded)
output_layer = layers.Dense(input_dim, activation='sigmoid')(decoded)
# Autoencoder model
autoencoder = models.Model(input_layer, output_layer)
# Compile the model
autoencoder.compile(optimizer='adam', loss='mse')
# Summary of the model
autoencoder.summary()
# Step 3: Train the Autoencoder
history = autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, validation_split=0.2)
# Step 4: Extract Features Using the Encoder
# Extract the encoder part of the autoencoder
encoder = models.Model(input_layer, latent_space)
# Encode the training and test data
X_train_encoded = encoder.predict(X_train)
X_test_encoded = encoder.predict(X_test)
# Step 5: Build and Train a Classifier
# Build a classifier using the encoded features
classifier = RandomForestClassifier(n_estimators=100, random_state=42)
# Train the classifier
classifier.fit(X_train_encoded, y_train)
# Predict on the test set
y_pred = classifier.predict(X_test_encoded)
# Step 6: Evaluate Performance
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print(f"Classification Report:\n{report}")
# Optional: Evaluate using original features for comparison
classifier_original = RandomForestClassifier(n_estimators=100, random_state=42)
classifier_original.fit(X_train, y_train)
y_pred_original = classifier_original.predict(X_test)
accuracy_original = accuracy_score(y_test, y_pred_original)
report_original = classification_report(y_test, y_pred_original)
print(f"Accuracy with Original Features: {accuracy_original}")
print(f"Classification Report with Original Features:\n{report_original}")
